{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_url = \"https://eprocure.gov.in/cppp/resultoftendersnew/mmpdata/byUVhOellXMD1BMTNoMVpteHZiMlE9QTEzaDFBMTNoMUExM2gxTWpBeU1BPT1BMTNoMU1RPT0=?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = requests.get(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #attempt 1 - success\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "import csv\n",
    "from urllib.request import urlopen\n",
    "import lxml.html as lh\n",
    "\n",
    "\n",
    "#COLUMNS = (\"SINO\",\"AOC\",\"epub\", \"title\",\"state\")\n",
    "#f.write(COLUMNS)\n",
    "#put page range and get only table)\n",
    "baseurl = \"https://eprocure.gov.in/cppp/latestactivetendersnew/mmpdata/byYzJWc1pXTjBBMTNoMWMyVnNaV04wQTEzaDFjSFZpYkdsemFHVmtYMlJoZEdVPUExM2gxVGtoTg=?\"\n",
    "for page in range(1,20):\n",
    "        h = {\"Cookie\": \"li=https%3A%2F%2Feprocure.gov.in%2Fcppp%2Fcancelledtenders; has_js=1; cookieWorked=yes; SSESS4e4a4d945e1f90e996acd5fb569779de=XbXDqjylwmrH0pAE-MEF55tkmmoTErEMbY6F3iklDCE\"}\n",
    "        r = requests.get(baseurl +'page='+ str(page),headers = h)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser') \n",
    "        #print(soup)\n",
    "        table = soup.find(\"table\")\n",
    "        table_new = table.findAll('tr')\n",
    "        with open('output.csv', 'a', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                for items in table_new:\n",
    "                        data = [item.get_text(strip=True) for item in items.find_all(['th','td'])]\n",
    "                        print(data)\n",
    "                        writer.writerow(data) \n",
    "        \n",
    "    #possibly to get all the links in the table (need to click on them and return data from in there)\n",
    "    #for anchor in table.findAll('a'):\n",
    "        #if not anchor: finaAll returns empty list, .find() return None\n",
    "            #continue\n",
    "        #href = anchor['href']    \n",
    "        #print (href)\n",
    "        #print (anchor.text)\n",
    "#create a csv and text from tables in\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt 2\n",
    "dataframe = []\n",
    "COLUMNS = ['SINO','AOC', 'epub', 'title', 'state']\n",
    "baseurl = \"https://eprocure.gov.in/cppp/resultoftendersnew/mmpdata/byUVhOellXMD1BMTNoMVpteHZiMlE9QTEzaDFBMTNoMUExM2gxTWpBeU1BPT1BMTNoMU1RPT0=?\"\n",
    "for page in range(1,10):\n",
    "    r = requests.get(baseurl +'page='+ str(page))\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')   \n",
    "    table = soup.find(\"table\", {'class': 'list_table'})# Find the \"table\" tag in the page\n",
    "    tbody = table.find('tbody')\n",
    "    rows = table.find_all(\"tr\") # Find all the \"tr\" tags in the table\n",
    "    cy_data = [] \n",
    "    for row in rows:\n",
    "        cells = row.find_all(\"td\") #  Find all the \"td\" tags in each row \n",
    "        cells = cells[0:5] # Select the correct columns\n",
    "        cy_data.append([cell.text for cell in cells]) # For each \"td\" tag, get the text inside it\n",
    "    dataframes.append(pd.DataFrame(cy_data, columns=COLUMNS).drop(0, axis=0))\n",
    "            \n",
    "#seems to be printing the same ten values again and again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://eprocure.gov.in/cppp/tendersfullviewmmp/Mjc1MjY4NDE=A13h1VmpGYWExTXlTWGxTYkdoUFZqSm9jbHBJYjNkUFVUMDk=A13h1VmpGYWExTXlTWGxTYkdoUFZqSm9jbHBJYjNkUFVUMDk=A13h1MTYxOTgxOTAzMw==A13h1VGVuZGVyL1Byb2MtQ292LzIwMjEvTkhNLTIyA13h1MjAyMV9ESEZXXzY0NDI2Xzc=\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'strip'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-561980d6cbee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0minsidetable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'td'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'v-a-top table-border table-border-right border-top-none border-bottom-none'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0minsidetable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m#table_inner = div.findAll('table')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m         \u001b[0;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2173\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   2174\u001b[0m             \u001b[0;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: ResultSet object has no attribute 'strip'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "#attempt3 - active tenders\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "import csv\n",
    "from urllib.request import urlopen\n",
    "import lxml.html as lh\n",
    "\n",
    "# NOTE: to test from command line, use curl:\n",
    "# curl --cookie \"li=https%3A%2F%2Feprocure.gov.in%2Fcppp%2Fcancelledtenders; has_js=1; cookieWorked=yes; SSESS4e4a4d945e1f90e996acd5fb569779de=XbXDqjylwmrH0pAE-MEF55tkmmoTErEMbY6F3iklDCE\" --referer \"https://eprocure.gov.in/\" https://eprocure.gov.in/cppp/tendersfullviewmmp/Mjc0NDkwNDM=A13h1VmpGYWExTXlTWGxTYkdoUFZqSm9jbHBJYjNkUFVUMDk=A13h1VmpGYWExTXlTWGxTYkdoUFZqSm9jbHBJYjNkUFVUMDk=A13h1MTYxOTczMTgzNw==A13h1c21jL2Nvbi9FVGVuZGVyTm8gMy85LzIwMjEtMjI=A13h1MjAyMV9ETUFfNjgwMzcwXzE=  | grep \"Tender Details\"\n",
    "#COLUMNS = (\"orgname\",\"orgtype\",\"tendertitle\",\"tenderrefno\",\"tendercateg\",\"tendertype\", \"Prodcategory\",\"tenderfee\",\"EMD\",\"Location\",\"Bidopeningdate\", \"docdownloadstart\",\"docdownloadend\",\"Bidsubmissionstart\", \"workdesc\",\"name\",\"address\")\n",
    "#f.write(COLUMNS)\n",
    " #possibly to get all the links in the table (need to click on them and return data from in there)\n",
    "#put page range and get only table\n",
    "#old: \"Cookie\": \"li=https%3A%2F%2Feprocure.gov.in%2Fcppp%2Fcancelledtenders; has_js=1; cookieWorked=yes; SSESS4e4a4d945e1f90e996acd5fb569779de=XbXDqjylwmrH0pAE-MEF55tkmmoTErEMbY6F3iklDCE\n",
    "\n",
    "baseurl = \"https://eprocure.gov.in/cppp/latestactivetendersnew/mmpdata/byYzJWc1pXTjBBMTNoMWMyVnNaV04wQTEzaDFjSFZpYkdsemFHVmtYMlJoZEdVPUExM2gxVGtoTg=?\"\n",
    "\n",
    "for page in range(1):\n",
    "        r = requests.get(baseurl +'page='+ str(page))\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        table = soup.find('table')\n",
    "        #print(table)\n",
    "        for row in table.find_all(\"tr\")[1:]:\n",
    "            fifth_col = row('td')[4].find('a').get(\"href\")\n",
    "            print(fifth_col)\n",
    "            h = {\"Referer\": \"https://eprocure.gov.in/\", \"Cookie\": \"li=https%3A%2F%2Feprocure.gov.in%2Fcppp%2Fcancelledtenders; has_js=1; cookieWorked=yes; SSESS4e4a4d945e1f90e996acd5fb569779de=XbXDqjylwmrH0pAE-MEF55tkmmoTErEMbY6F3iklDCE\"}\n",
    "            inner_response = requests.get(fifth_col, headers=h)\n",
    "            inner_soup = BeautifulSoup(inner_response.content, 'html.parser')\n",
    "            #print(inner_soup)\n",
    "            #if \"Invalid parameter\" in str(inner_soup):\n",
    "            #    raise Exception(\"Invalid parameter found. Did you forget to set the cookies?\")\n",
    "             #   with open(\"soups.html\", \"w\") as text_file:\n",
    "              #       print(inner_soup, file=text_file)\n",
    "            div = inner_soup.findAll('table')\n",
    "            #print(div)\n",
    "            for text in div:\n",
    "                insidetable = text.findAll('td', {'class':'v-a-top table-border table-border-right border-top-none border-bottom-none'})\n",
    "                \n",
    "                \n",
    "            #table_inner = div.findAll('table')\n",
    "            #print(table_inner)\n",
    "            #text = inner_soup.findAll('table', attr = {\"id\":\"tenderDetailDivTd\"})\n",
    "            #print(text)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    #text = inner_soup.findAll(table, attr = {\"id\":\"tenderDetailDivTd\"})\n",
    "    #print(text)\n",
    "    \n",
    "    #inner_table_2 = inner_soup.findAll('table')[1]\n",
    "    #print(inner_table_2)\n",
    "    #inner_table_4 = inner_soup.findAll('table')[3]\n",
    "    #inner_table_6 = inner_soup.findAll('table')[5]\n",
    "    #inner_table_6 = inner_soup.findAll('table')[5]\n",
    "    \n",
    "    #rows = inner_table_2.findAll(\"tr\", attr ={\"id\":\"tenderDetailDivTd\"})\n",
    "    #print(rows)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #create a csv and text from tables in\n",
    "    #with open('output1.csv', 'a', newline='') as f:\n",
    "     #   writer = csv.writer(f)\n",
    "      #  for items in table_new:\n",
    "       #     data = [item.get_text(strip=True) for item in items.find_all(['th','td'])]\n",
    "        #    print(data)\n",
    "         #   writer.writerow(data)       \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tag in fifth_col:\n",
    "             #   link = tag.get(\"href\", None)\n",
    "              #  print(link)\n",
    "        \n",
    "        #table_new = table.findAll('tr')\n",
    "        \n",
    "        \n",
    "        #for row in soup.findAll('table'):\n",
    "          #      row = table.findAll('tr')\n",
    "        \n",
    "            #    fifth_column_tags = row.findAll('a')[4].contents\n",
    "        \n",
    "        #a_tags = table.findAll('a')\n",
    "                #print(fifth_column_tags)\n",
    "        #for tag in a_tags:\n",
    "         #   print(tag)\n",
    "          #  link = tag.get(\"href\", None)\n",
    "           # print(link)\n",
    "            \n",
    "#for row in soup.findAll('table')[0].table.findAll('tr'):\n",
    " #   first_column = row.findAll('th')[0].contents\n",
    "  #  third_column = row.findAll('td')[2].contents\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table_inner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b59585796891>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_inner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'table_inner' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
